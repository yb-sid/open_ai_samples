{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain # chain for routing between multiple prompts\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser # use LLM to route between subchains\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chain \n",
    "\n",
    "Route an input to a chain , based on what is input\n",
    "\n",
    "Multiple sub-chains ,  routerchain decides which chain to pass input to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using subjects\n",
    "# define String templates to be used later\n",
    "physics_template = \"\"\"You are a Physics Professor. You need to answers questions about physics in a concise and \n",
    "easy to understand manner. When you do now know the answer to a question , you will admit it.\n",
    "Here is the question : \n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "maths_template = \"\"\"You are the best Mathematician ever. You are great at answering and solving Math questions.\n",
    "you are so good that you can break up hard problems and into components , solve these components independently, \n",
    "and then put them together to answer broader question.\n",
    "Here's the question/problem:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "history_template = \"\"\"\n",
    "You are a historian. You have excellent knowledge and understanding of people , events and contexts from a range\n",
    "of historical periods. YOu have the ability to think , reflect , debate , discuss and  evaluate the past. You have\n",
    "the ability to reason and answer historical questions.\n",
    "Here's the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cs_template = \"\"\" \n",
    "You are a prefessional Computer Scientist. You have strong problem solving skills and excellent knowledge of \n",
    "computer-sceince concepts. You are able to answer coding questions and able to provide imperative steps to \n",
    "implement the solution. You know the tradeoffs between different solutions and are able to select the best solution\n",
    "based on question's requirement.\n",
    "Here's the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "# here use of {input} is important , for chaining and ouput parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a structure for more information about each prompt.\n",
    "# this structure is passed to router-chain , so router chain can decide which sub-chain to use\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\" : \"physics\",\n",
    "        \"description\" : \"prompt for answering physics question\",\n",
    "        \"prompt_template\" : physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"maths\",\n",
    "        \"description\" : \"prompt for answering mathematics related question\",\n",
    "        \"prompt_template\" : maths_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\",\n",
    "        \"description\":\"prompt for answering history related questions\",\n",
    "        \"prompt_template\" : history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"computer science\",\n",
    "        \"description\" : \"prompt for answering computer science questions\",\n",
    "        \"prompt_template\" : cs_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MultipromptChain - used when routing between different types of prompt templates\n",
    "- LLMRouterChain - use language model itself to route between different subchains , the `description` and `name`\n",
    "  provided above will be used here\n",
    "- RouterParser - LLM output into a dictionary , which can be used later to select input for subchains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "chat_model = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create destination chains \n",
    "# this will be used by LLMRouterChain\n",
    "\n",
    "destination_chains = {} # map name of subject to a chain\n",
    "for prompt_info in prompt_infos:\n",
    "    name = prompt_info['name']\n",
    "    prompt_template = prompt_info['prompt_template']\n",
    "    prompt = PromptTemplate.from_template(template = prompt_template)\n",
    "    chain = LLMChain(llm = chat_model , prompt= prompt )\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# import pprint\n",
    "# pprint.pprint(destination_chains)\n",
    "\n",
    "destinations = [f\"{p['name']} : {p['description']}\" for p in prompt_infos] # list of string -> `subject : description`\n",
    "\n",
    "destination_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a default prompt , when a question of different subject is asked\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=chat_model , prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given a raw text input to a language model, select the select the model prompt best suited for input.\n",
      "You will be given names of prompt and a description of what the prompt can do. You may also revise the input\n",
      "if it leads to better response from language model.\n",
      "\n",
      "<<FORMATTING>>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\" : string - name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\" : string - a potentially modified version of original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below or it can be \"DEFAULT\" \n",
      "if the input is not well suited for any of the candidate prompts. Do not add or generate \"destination\" on your own.\n",
      "\n",
      "REMEMBER: \"next_inputs\" can be same as original input if you do not think any modification is needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >> \n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (remember to include the ```json)>> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define a template to be used by LLM to route between different chains\n",
    "# the formatting and words used in this template are important and used by router chain to generate intermeditary ouput\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"\n",
    "Given a raw text input to a language model, select the select the model prompt best suited for input.\n",
    "You will be given names of prompt and a description of what the prompt can do. You may also revise the input\n",
    "if it leads to better response from language model.\n",
    "\n",
    "<<FORMATTING>>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\" : string - name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\" : string - a potentially modified version of original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below or it can be \"DEFAULT\" \n",
    "if the input is not well suited for any of the candidate prompts. Do not add or generate \"destination\" on your own.\n",
    "\n",
    "REMEMBER: \"next_inputs\" can be same as original input if you do not think any modification is needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >> \n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>> \n",
    "\"\"\" # quadruple and double {} are for placeholders in multiple line f-strings\n",
    "# destination , next_inputs are expected by RouterOuputParserClass\n",
    "#print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations = destination_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template = router_template,\n",
    "    input_variables = [\"input\"],\n",
    "    output_parser = RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm= chat_model , prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(\n",
    "    router_chain= router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'What is subconcious ?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The subconscious mind refers to the part of our mind that operates below the level of conscious awareness. It is responsible for storing and processing information, beliefs, memories, and emotions that are not currently in our conscious awareness. The subconscious mind influences our thoughts, feelings, and behaviors, often without us being aware of it. It is believed to play a significant role in shaping our personality, habits, and responses to various situations.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is subconcious ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
