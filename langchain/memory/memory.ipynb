{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. ConversationBufferWindowMemory\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. ConversationBufferWindowMemory\n",
    "#@tag:notebookOutputLayout , use to format ouput\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openai key\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chat model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chat_model = ChatOpenAI(temperature=0.0,max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(\n",
    "    k=2\n",
    ")  # remember recent 2 conversation pairs(input,output)\n",
    "\n",
    "conversation = ConversationChain(memory=window_memory, llm=chat_model, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: how long will Sun live? Answer in 50 words or less\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The Sun is currently about 4.6 billion years old and is expected to live for another 5 billion years. However, as it ages, it will expand into a red giant and eventually shed its outer layers, becoming a white dwarf. So, in total, the Sun's lifespan is estimated to be around 10 billion years.\n",
      "memory is : Human: how long will Sun live? Answer in 50 words or less\n",
      "AI: The Sun is currently about 4.6 billion years old and is expected to live for another 5 billion years. However, as it ages, it will expand into a red giant and eventually shed its outer layers, becoming a white dwarf. So, in total, the Sun's lifespan is estimated to be around 10 billion years.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: how long will Sun live? Answer in 50 words or less\n",
      "AI: The Sun is currently about 4.6 billion years old and is expected to live for another 5 billion years. However, as it ages, it will expand into a red giant and eventually shed its outer layers, becoming a white dwarf. So, in total, the Sun's lifespan is estimated to be around 10 billion years.\n",
      "Human: How fast can a mass of 70Kgs travel realistically? Answer in 50 Words or less\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The speed at which a mass of 70 kilograms can travel realistically depends on various factors such as the mode of transportation and the conditions. For example, a person running can reach speeds of around 20 kilometers per hour, while a car can travel at speeds of up to 200 kilometers per hour.\n",
      "memory is : Human: how long will Sun live? Answer in 50 words or less\n",
      "AI: The Sun is currently about 4.6 billion years old and is expected to live for another 5 billion years. However, as it ages, it will expand into a red giant and eventually shed its outer layers, becoming a white dwarf. So, in total, the Sun's lifespan is estimated to be around 10 billion years.\n",
      "Human: How fast can a mass of 70Kgs travel realistically? Answer in 50 Words or less\n",
      "AI: The speed at which a mass of 70 kilograms can travel realistically depends on various factors such as the mode of transportation and the conditions. For example, a person running can reach speeds of around 20 kilometers per hour, while a car can travel at speeds of up to 200 kilometers per hour.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: how long will Sun live? Answer in 50 words or less\n",
      "AI: The Sun is currently about 4.6 billion years old and is expected to live for another 5 billion years. However, as it ages, it will expand into a red giant and eventually shed its outer layers, becoming a white dwarf. So, in total, the Sun's lifespan is estimated to be around 10 billion years.\n",
      "Human: How fast can a mass of 70Kgs travel realistically? Answer in 50 Words or less\n",
      "AI: The speed at which a mass of 70 kilograms can travel realistically depends on various factors such as the mode of transportation and the conditions. For example, a person running can reach speeds of around 20 kilometers per hour, while a car can travel at speeds of up to 200 kilometers per hour.\n",
      "Human: What are consequenses of humanity on earth? Answer in 50 words or less\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The consequences of humanity on Earth are vast and varied. Some of the major consequences include deforestation, pollution, climate change, loss of biodiversity, and depletion of natural resources. These actions have led to negative impacts on ecosystems, wildlife, and the overall health of the planet.\n",
      "memory is : Human: How fast can a mass of 70Kgs travel realistically? Answer in 50 Words or less\n",
      "AI: The speed at which a mass of 70 kilograms can travel realistically depends on various factors such as the mode of transportation and the conditions. For example, a person running can reach speeds of around 20 kilometers per hour, while a car can travel at speeds of up to 200 kilometers per hour.\n",
      "Human: What are consequenses of humanity on earth? Answer in 50 words or less\n",
      "AI: The consequences of humanity on Earth are vast and varied. Some of the major consequences include deforestation, pollution, climate change, loss of biodiversity, and depletion of natural resources. These actions have led to negative impacts on ecosystems, wildlife, and the overall health of the planet.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"how long will Sun live? Answer in 50 words or less\"))\n",
    "print(f\"memory is : {window_memory.buffer}\")\n",
    "print(conversation.predict(input=\"How fast can a mass of 70Kgs travel realistically? Answer in 50 Words or less\"))\n",
    "print(f\"memory is : {window_memory.buffer}\")\n",
    "print(conversation.predict(input=\"What are consequenses of humanity on earth? Answer in 50 words or less\"))\n",
    "print(f\"memory is : {window_memory.buffer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Conclusion:\n",
    " \n",
    " ConversationBufferWithWindow maintains a window of most recent `k` conversations between human and AI.\n",
    " Each conversation is of pair(human,AI). In real applications `k` should be sufficiently large.\n",
    "\n",
    " Prevents memory to grow out of context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationTokenBufferMemory\n",
    "\n",
    "Used to save memory on tokens used , since LLMs use tokens as cost measure and context limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Is AI overtaking world?\n",
      "AI: Seems so.\n",
      "Human: Can capitalism be controlled?\n",
      "AI: not unless humans give up on greed\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=chat_model,max_token_limit=50)\n",
    "\n",
    "memory.save_context({\"input\":\"Are Platypus mammals?\"},{\"output\":\"They are freak of nature\"})\n",
    "memory.save_context({\"input\":\"Is AI overtaking world?\"},{\"output\":\"Seems so.\"})\n",
    "memory.save_context({\"input\":\"Can capitalism be controlled?\"},{\"output\":\"not unless humans give up on greed\"})\n",
    "\n",
    "\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Only last `max_token_limit` length of tokens are kept in memory (most recent) and given to LLM as context. \n",
    "Does not necessarylity keep (Human,AI) in pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationSummaryMemory\n",
    "\n",
    "Use LLM to generate summary of conversation so far , and use it as memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=chat_model, max_token_limit=100) # if more tokens all text , if less than summarized text\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n",
      "Human: How Can I convince the team about AI revolution?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To convince the team about the AI revolution, it's important to present a compelling case that highlights the potential benefits and opportunities it can bring to the company. Here are a few strategies you can consider:\\n\\n1. Educate them about the current AI landscape: Start by providing an overview of the advancements in AI technology and how it is being successfully implemented in various industries. Share examples of companies that have embraced AI and the positive impact it has had on their operations, productivity, and profitability.\\n\\n2. Highlight the competitive advantage: Emphasize how adopting AI can give your company a competitive edge in the market. Discuss how AI can automate repetitive tasks, improve decision-making processes, and enhance customer experiences. Show them how AI can help the company stay ahead of the curve and outperform competitors.\\n\\n3. Address concerns and misconceptions: Many people have concerns about AI, such as job displacement or ethical implications. Acknowledge these concerns and address them head-on. Explain how AI can augment human capabilities rather than replace them, and how it can create new job opportunities. Discuss the ethical considerations and the steps your company is taking to ensure responsible AI implementation.\\n\\n4. Showcase successful AI projects: If your company has already implemented AI in some areas, share success stories and tangible results. Highlight the positive impact it has had on efficiency, cost savings, or customer satisfaction. This will help build credibility and demonstrate the potential of AI within your organization.\\n\\n5. Offer training and support: Assure your team that you will provide the necessary training and support to help them adapt to AI technologies. Offer resources, workshops, or external training programs to help them upskill and embrace the AI revolution.\\n\\nRemember, it's important to tailor your approach to the specific needs and concerns of your team. Be prepared to answer questions and address any doubts they may have. Good luck with your presentation!\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat_model, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"How Can I convince the team about AI revolution?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings and discuss the schedule for the day, which includes a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The human then asks how to convince the team about the AI revolution. The AI provides strategies, including educating them about the current AI landscape, highlighting the competitive advantage, addressing concerns and misconceptions, showcasing successful AI projects, and offering training and support. The AI encourages tailoring the approach to the specific needs and concerns of the team.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "ConversationSummaryMemory stores most recent AI response with token limit , and all previous conversation detail goes into `summary` key of memory.\n",
    "\n",
    "Example : \n",
    "- Two conversation took place and token limit is reached.\n",
    "- next conversation , first memory is summarized and placed in system text.\n",
    "- Then left over tokens are taken and used to answer chat request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two other types of useful memories to look into :\n",
    "\n",
    "- Vector data memory\n",
    "- Entity memory \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
