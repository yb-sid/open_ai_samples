{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document splitting happens after data is loaded  \n",
    "but before storing into vector store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv , find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting of chunks has to be done in a way so information and context meaning is not lost.\n",
    "\n",
    "splitting has `chunk_size` and `chunk_overlap`\n",
    "\n",
    "chunk overlap is a sliding window of text , at the end of a chunk and start of next chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langchain.text_splitter has following splitters\n",
    "\n",
    "- *CharacterTextSplitter* : Implementation of splitting text that looks at characters\n",
    "\n",
    "- *MarkdownHeaderTextSplitter* : Implementation of splitting markdown files based on specified headers\n",
    "\n",
    "- *TokenTextSplitter* : splitting texts that look at token\n",
    "\n",
    "- *SentenceTransformerTokenTextSplitter* : implementation of splitting text that sentence and tokens\n",
    "\n",
    "- *RecursiveCharacterTextSplitter* : splitting text using characters. Recursively tries to split by different characters\n",
    "\n",
    "- *NLTKTextSplitter* : looks at sentences using NLTK (Natural Language tool kit)\n",
    "\n",
    "- *SpacyTextSplitter* : looks at sentences using spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text splitters\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter , CharacterTextSplitter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOY use cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz' \n",
    "r_splitter.split_text(text1) # no splitting as lenght of text is 26 == chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2) # split on 26th char `z` , take 4 char from last chunk `wxyz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3) # character splitter by default , splits on \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text) # separated text on \\n\\n , even if chunk is smaller than size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"] # lookback sentence regex\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use splitting on an actual PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"ml_doc.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we'll start to  talk a bit about machine learning.  \\nBy way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \\nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I'm actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck\", metadata={'source': 'ml_doc.pdf', 'page': 0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs) > len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text = \"foo bar bazzyfoo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(token_text) # last word is split into 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenTextSplitter(encoding_name=\"cl100k_base\",\n",
    "                                   model_name=\"gpt-3.5-turbo\",\n",
    "                                   chunk_size = 10,\n",
    "                                   chunk_overlap = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_tokens = token_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=' Ng):  Okay. Good morning. Welcome to', metadata={'source': 'ml_doc.pdf', 'page': 0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokens[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]  # metadata has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using of text splitter is to get sematically related chunks of data.\n",
    "\n",
    "Need to move it to a vector store before querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
