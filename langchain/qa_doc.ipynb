{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A over a document or user data.\n",
    "\n",
    "run query agaist data from pdfs , company internal files.  \n",
    "** Use of embedding models and vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA # A chain specific for Q/A style converstaion\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display,Markdown\n",
    "\n",
    "# load csv file \n",
    "\n",
    "loader = CSVLoader(file_path = \"qa_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install docarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs can work with few thousand words at a time (context length / token limit)\n",
    "\n",
    "How to answer questions about large and multiple documents\n",
    "Answer - user embeddings and vector stores\n",
    "\n",
    "Embeddings :\n",
    "- embeddings create numerical rep for pieces of text\n",
    "- this captures semantic meaning of the piece of text\n",
    "- similar text will have similar vector\n",
    "\n",
    "Vector Database/Store:\n",
    "- a way to store vector representations\n",
    "- populate with chunks of texts \n",
    "- pieces of texts smaller than original doc\n",
    "- then create an embedding for each of the chunk to create index\n",
    "- during runtime find text most relevant to incoming query\n",
    "\n",
    "When a query comes -> first create an embedding for query\n",
    "compare the embedding to all vectors , pick most similar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector index - helper\n",
    "# change import in _sql_record_manager\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator( \n",
    "    # this will cause RateLimitError for token limit\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description |\n",
       "| --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | UPF 50+ rated, 100% polyester, wrinkle-resistant, front and back cape venting, two front bellows pockets |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | UPF 50+ rated, 52% polyester and 48% nylon, machine washable and dryable, front and back cape venting, two front bellows pockets |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | UPF 50+ rated, 71% Nylon, 29% Polyester, 100% Polyester knit mesh, wrinkle resistant, front and back cape venting, two front bellows pockets |\n",
       "| Sun Shield Shirt by | UPF 50+ rated, 78% nylon, 22% Lycra Xtra Life fiber, wicks moisture, fits comfortably over swimsuit, abrasion resistant |\n",
       "\n",
       "All four shirts provide UPF 50+ sun protection, blocking 98% of the sun's harmful rays. The Men's Tropical Plaid Short-Sleeve Shirt is made of 100% polyester and is wrinkle-resistant. The Men's Plaid Trop"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now use index to ask questions\n",
    "\n",
    "query = \"Please list all shirts with sun protection in a table in markdown and summarize each one.\"\n",
    "\n",
    "response = index.query(query)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# load docs\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n",
    "# get embedding model\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# embed = embedding.embed_query(query)\n",
    "# print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176510\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(docs):\n",
    "  \"\"\"\n",
    "  Counts the total number of tokens in a list of documents.\n",
    "\n",
    "  Args:\n",
    "    docs: A list of documents.\n",
    "\n",
    "  Returns:\n",
    "    The total number of tokens.\n",
    "  \"\"\"\n",
    "  total_tokens = 0\n",
    "  encoding = tiktoken.encoding_for_model(\"text-embedding-ada-002\") # default-text-embedding-ada-002\n",
    "  for doc in docs:\n",
    "    total_tokens += len(encoding.encode(doc.page_content) )\n",
    "  return total_tokens\n",
    "\n",
    "total_tokens = count_tokens(docs)\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87415\n",
      "89095\n"
     ]
    }
   ],
   "source": [
    "# create vector db \n",
    "# token count is more than limit , break up \n",
    "docs_len = len(docs)\n",
    "half = docs_len//2\n",
    "docs_set_one = docs[:half]\n",
    "print(count_tokens(docs_set_one))\n",
    "docs_set_two = docs[half:]\n",
    "print(count_tokens(docs_set_two))\n",
    "\n",
    "# calls embedding API\n",
    "# db_one = DocArrayInMemorySearch.from_documents(documents=docs_set_one , embedding=embedding)\n",
    "# need logic to bypass ratelimit error\n",
    "# db_two = DocArrayInMemorySearch.from_documents(documents=docs_set_two , embedding=embedding) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Ipkgjb8eV212suWndEgA3XmD on tokens per min. Limit: 150000 / min. Current: 101754 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Ipkgjb8eV212suWndEgA3XmD on tokens per min. Limit: 150000 / min. Current: 89203 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Ipkgjb8eV212suWndEgA3XmD on tokens per min. Limit: 150000 / min. Current: 77099 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "# RateLimit error : 150000/min bottleneck\n",
    "#db_all = DocArrayInMemorySearch.from_documents(documents=docs , embedding=embedding)\n",
    "\n",
    "vector_db = DocArrayInMemorySearch.from_documents(documents=docs_set_one , embedding=embedding)\n",
    "added_ids = vector_db.add_documents(docs_set_two) # add set two docs to initial vector db \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "temp_query = \"Please suggest a shirt with sunblocking for men\"\n",
    "\n",
    "filtered_docs = vector_db.similarity_search(temp_query)\n",
    "\n",
    "print(len(filtered_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note :\n",
    "\n",
    "Similarity search result of one vecto_db is different than   \n",
    "similarty search on two sub_vector db and combining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# response_one = db_one.similarity_search(temp_query)\n",
    "# response_two = db_two.similarity_search(temp_query)\n",
    "# response_docs = response_one + response_two\n",
    "# print(len(response_one))\n",
    "# print(len(response_two))\n",
    "# print(len(response_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Men's Plaid Tropic Shirt - 374\n",
    "Sun Shield Shirt - 255\n",
    "Girls' Ocean Breeze Long-Sleeve Stripe Shirt - 293\n",
    "Women's Tropical Plaid Shirt - 87\n",
    "Men's TropicVibe Shirt, Short-Sleeve - 535\n",
    "Men's Tropical Plaid Short-Sleeve Shirt - 618\n",
    "Women's Tropical Tee, Sleeveless - 679\n",
    "Girls' Beachside Breeze Shirt, Half-Sleeve - 617\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a retriever to run Questions against \n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "query_docs = \"\".join([doc.page_content for doc in filtered_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = chat_model.call_as_llm(f\"\"\"{query_docs} \\n Question:\\n\n",
    "Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt Name | Description | Summary |\n",
       "|------------|-------------|---------|\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | This shirt offers UPF 50+ sun protection, is wrinkle-free, and quickly evaporates perspiration. It has front and back venting and two front bellows pockets. | Lightweight and comfortable shirt with high sun protection and additional features for outdoor activities. |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | This shirt has built-in UPF 50+ sun protection, is wrinkle-resistant, and has front and back venting and two front bellows pockets. | Lightweight and relaxed-fit shirt with excellent sun protection and added features for comfort. |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | This shirt is rated UPF 50+ and is made of wrinkle-resistant polyester. It has front and back venting and two front bellows pockets. | Light and relaxed-fit shirt with superior sun protection and convenient pockets. |\n",
       "| Sun Shield Shirt | This high-performance sun shirt is UPF 50+ rated and made of moisture-wicking fabric. It fits comfortably over swimsuits and is abrasion-resistant. | Soft and fitted shirt with excellent sun protection, suitable for outdoor activities and swimwear. |\n",
       "\n",
       "Overall, all the shirts listed provide high sun protection with UPF 50+ ratings. They are made of lightweight and comfortable fabrics, have additional features such as venting and pockets, and are suitable for various outdoor activities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(llm_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Methods :\n",
    "\n",
    "`stuff` method : simplest , all data into prompt and call LLM once\n",
    " - pros : single call to LLM\n",
    " - con : context length can be a bottleneck\n",
    "\n",
    " `map_reduce` method : each chunks call to LLM (map), and again call to LLM to combine (reduce)\n",
    " - pro : context limit won't be a problem , since parallel calls \n",
    " - con : RateLimitError will be bottleneck , all calls are individual , so context might be lost\n",
    "\n",
    " `refine` method : calls LLM iteratively , and combines response \n",
    "  - this is slower as calls take time and each time result is built upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ") # no call to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\"\n",
    "\n",
    "retreiver_reponse = qa_stuff(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(retreiver_reponse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
